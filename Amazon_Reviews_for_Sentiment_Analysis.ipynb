{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarK920/NLP-Projects-/blob/main/Amazon_Reviews_for_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Reading and loading"
      ],
      "metadata": {
        "id": "YrauLPcv0wd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import bz2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "GSJ2eqdux1ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Amazonreviews.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1IU77mfzOcE",
        "outputId": "d3e42bd2-a9e5-4812-f604-b6b5b43db82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Amazonreviews.zip\n",
            "  inflating: test.ft.txt.bz2         \n",
            "  inflating: train.ft.txt.bz2        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = bz2.BZ2File('/content/train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('/content/test.ft.txt.bz2')"
      ],
      "metadata": {
        "id": "KHeImObWxt3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_extract(file):\n",
        "    texts, labels = [], []\n",
        "    for line in file:\n",
        "        x = line.decode('utf-8')  # decode binary to string\n",
        "        labels.append(int(x[9]) - 1)  # extract labels\n",
        "        texts.append(x[10:].strip())  # extract texts\n",
        "    print('Done !')\n",
        "    return np.array(labels), texts"
      ],
      "metadata": {
        "id": "TA6W3wmPz1Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels, train_texts = load_extract(train_file)\n",
        "test_labels, test_texts = load_extract(test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5_Aj5ndz549",
        "outputId": "cd7c27da-58d1-4adc-f215-460b80094b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done !\n",
            "Done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "n01tNd25z57l",
        "outputId": "c9ff3e5b-0b62-4a4f-d454-83cd20f57892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section\n",
        "In this section i will be doing LSTM model for sentiment prediction. but first i have to preprocess the data"
      ],
      "metadata": {
        "id": "hoCqQWQg4d-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "TRD2AJat7Isi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Replaces digits with '0'.\n",
        "\n",
        "- Removes URLs and links.\n",
        "\n",
        "- Converts all characters to lowercase.\n",
        "\n",
        "- Tokenizes the text into words.\n",
        "\n",
        "- Removes English stopwords.\n",
        "\n",
        "- Lemmatizes each word.\n",
        "\n",
        "- Joins the words back into a string."
      ],
      "metadata": {
        "id": "VfiOKOKAMiBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGfzQeDk8BAp",
        "outputId": "8a6dba3d-09e9-4f6c-ef22-84574a6d0181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def clean_texts(texts):\n",
        "    stwords = stopwords.words('english')\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    temp_texts = []\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        text = re.sub('\\d', '0', texts[i])  # replace every digit with 0\n",
        "        if 'www.' in text or 'http:' in text or 'https:' in text or '.com' in text:  # remove links and urls\n",
        "            text = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \" \", text)\n",
        "\n",
        "        text = re.sub('[^a-zA-Z]', ' ', text)  # anything which is not a character replace with whitespace char\n",
        "        text = text.lower()\n",
        "        text = word_tokenize(text)  # tokenize the text\n",
        "        text = [word for word in text if not word in stwords]  # remove stopwords\n",
        "        text = [lemmatizer.lemmatize(word) for word in text]  # lemmatization\n",
        "        text = ' '.join(text)\n",
        "\n",
        "        temp_texts.append(text)\n",
        "\n",
        "    print('--100%--Done!')\n",
        "    return temp_texts\n"
      ],
      "metadata": {
        "id": "gqlM-uM04ob2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Processing Training data')\n",
        "train_texts = clean_texts(train_texts)\n",
        "print('\\nProcessing Test data')\n",
        "test_texts = clean_texts(test_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G_l92NA4oev",
        "outputId": "b093384f-b562-4c20-c70e-018d50f7d3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Training data\n",
            "--100%--Done!\n",
            "\n",
            "Processing Test data\n",
            "--100%--Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "yWXPb7JmKLwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Assuming you have train_texts, test_texts, train_labels, and test_labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "T22210x_4ohh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "1KxseOdfPHoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "X_train_pad = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=100, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=100, padding='post', truncating='post')\n",
        "\n",
        "# Build and train an even simpler LSTM model\n",
        "model_lstm_simplest = Sequential()\n",
        "model_lstm_simplest.add(Embedding(input_dim=len(word_index) + 1, output_dim=16, input_length=100))\n",
        "model_lstm_simplest.add(LSTM(16))\n",
        "model_lstm_simplest.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_lstm_simplest.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 3 epochs\n",
        "history_lstm_simplest = model_lstm_simplest.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=3,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Access accuracy history during training\n",
        "accuracy_lstm_simplest = history_lstm_simplest.history['accuracy']\n",
        "val_accuracy_lstm_simplest = history_lstm_simplest.history['val_accuracy']\n",
        "\n",
        "# Print accuracy at each epoch\n",
        "for epoch, acc, val_acc in zip(range(1, 4), accuracy_lstm_simplest, val_accuracy_lstm_simplest):\n",
        "    print(f\"Epoch {epoch} - Training Accuracy: {acc:.4f} - Validation Accuracy: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLiITFnW4okZ",
        "outputId": "c82fd2c4-a832-4202-c613-9b0ffc3510cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "72000/72000 [==============================] - 26496s 368ms/step - loss: 0.5124 - accuracy: 0.7493 - val_loss: 0.2820 - val_accuracy: 0.8848\n",
            "Epoch 2/3\n",
            " 4829/72000 [=>............................] - ETA: 6:29:09 - loss: 0.2635 - accuracy: 0.8944"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next section i will use logistic regression model to classify"
      ],
      "metadata": {
        "id": "EisenK8wL1GF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Vectorization"
      ],
      "metadata": {
        "id": "4ryDeK-1IrZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Fitting data...')\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(train_texts) ; print('fit complete !')\n",
        "\n",
        "print('tranforming training set...')\n",
        "train_texts_vec = count_vect.transform(train_texts)\n",
        "\n",
        "print('tranforming test set...')\n",
        "test_texts_vec = count_vect.transform(test_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i81CqXdxBOri",
        "outputId": "78f71bb1-45db-497f-f6dd-abecda9bf7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting data...\n",
            "fit complete !\n",
            "tranforming training set...\n",
            "tranforming test set...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "Logistic Regression Model for text classification"
      ],
      "metadata": {
        "id": "ElqpQnGexvXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(n_jobs=-1, max_iter=150)\n",
        "lr_model.fit(train_texts_vec, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "X6bkOsbQWI88",
        "outputId": "88de06dc-41ff-4a06-daf6-cdba1b8b78cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=150, n_jobs=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=150, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=150, n_jobs=-1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr_model.predict(test_texts_vec)\n"
      ],
      "metadata": {
        "id": "mjsBriohWI_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:', accuracy_score(test_labels, pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEuwI8sTWJCq",
        "outputId": "ffb46771-ac7a-4551-f326-83e638984ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.900615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = test_texts[265]\n",
        "print(sample)\n",
        "\n",
        "sample_vec = count_vect.transform([sample])\n",
        "pred = lr_model.predict(sample_vec)\n",
        "print('\\npredicted label:',pred[0])\n",
        "print('actual label:', test_labels[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Oe7F3TXi9A",
        "outputId": "4a74ea5a-428e-4136-a03e-0f8174b2278a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big deal thing interesting album mia accent seriously beats singing layered tired clich vocals album anyone else would top final verdict bad music\n",
            "\n",
            "predicted label: 0\n",
            "actual label: 0\n"
          ]
        }
      ]
    }
  ]
}